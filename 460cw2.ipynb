{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "460cw2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZHONGCHUYUN/Deep_learning_cw/blob/master/460cw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QSOo2x0z2RK7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Coursework2: Convolutional Neural Networks "
      ]
    },
    {
      "metadata": {
        "id": "_gCOCiev2RLB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## instructions"
      ]
    },
    {
      "metadata": {
        "id": "6EmANXD12RLG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Please submit a version of this notebook containing your answers **together with your trained model** on CATe as CW2.zip. Write your answers in the cells below each question.\n",
        "\n",
        "A PDF version of this notebook is also provided in case the figures do not render correctly.\n",
        "\n",
        "**The deadline for submission is 19:00, Thu 14th February, 2019**"
      ]
    },
    {
      "metadata": {
        "id": "YofcaVy82RLK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setting up working environment "
      ]
    },
    {
      "metadata": {
        "id": "3qegujdS2RLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this coursework you will need to train a large network, therefore we recommend you work with Google Colaboratory, which provides free GPU time. You will need a Google account to do so. \n",
        "\n",
        "Please log in to your account and go to the following page: https://colab.research.google.com. Then upload this notebook.\n",
        "\n",
        "For GPU support, go to \"Edit\" -> \"Notebook Settings\", and select \"Hardware accelerator\" as \"GPU\".\n",
        "\n",
        "You will need to install pytorch by running the following cell:"
      ]
    },
    {
      "metadata": {
        "id": "78AdiVWx2RLT",
        "colab_type": "code",
        "outputId": "db64fc0b-5452-4a7c-be53-e68c7ebe9c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\r\u001b[K    0% |▏                               | 10kB 13.9MB/s eta 0:00:01\r\u001b[K    1% |▎                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K    1% |▌                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 40kB 2.1MB/s eta 0:00:01\r\u001b[K    2% |▉                               | 51kB 2.6MB/s eta 0:00:01\r\u001b[K    3% |█                               | 61kB 3.1MB/s eta 0:00:01\r\u001b[K    3% |█▏                              | 71kB 3.6MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 81kB 4.0MB/s eta 0:00:01\r\u001b[K    4% |█▌                              | 92kB 4.5MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 102kB 3.5MB/s eta 0:00:01\r\u001b[K    5% |█▉                              | 112kB 3.5MB/s eta 0:00:01\r\u001b[K    6% |██                              | 122kB 4.9MB/s eta 0:00:01\r\u001b[K    6% |██▏                             | 133kB 4.9MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 143kB 9.2MB/s eta 0:00:01\r\u001b[K    7% |██▌                             | 153kB 9.3MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 163kB 9.3MB/s eta 0:00:01\r\u001b[K    8% |██▉                             | 174kB 9.1MB/s eta 0:00:01\r\u001b[K    9% |███                             | 184kB 9.2MB/s eta 0:00:01\r\u001b[K    9% |███▏                            | 194kB 9.2MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 204kB 40.5MB/s eta 0:00:01\r\u001b[K    10% |███▌                            | 215kB 10.5MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 225kB 10.5MB/s eta 0:00:01\r\u001b[K    11% |███▉                            | 235kB 10.5MB/s eta 0:00:01\r\u001b[K    12% |████                            | 245kB 10.6MB/s eta 0:00:01\r\u001b[K    12% |████▏                           | 256kB 10.6MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 266kB 10.2MB/s eta 0:00:01\r\u001b[K    13% |████▌                           | 276kB 10.4MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 286kB 10.4MB/s eta 0:00:01\r\u001b[K    14% |████▉                           | 296kB 10.4MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 307kB 10.6MB/s eta 0:00:01\r\u001b[K    16% |█████▏                          | 317kB 45.2MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 327kB 44.5MB/s eta 0:00:01\r\u001b[K    17% |█████▌                          | 337kB 45.6MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 348kB 41.4MB/s eta 0:00:01\r\u001b[K    18% |█████▉                          | 358kB 41.8MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 368kB 48.7MB/s eta 0:00:01\r\u001b[K    19% |██████▏                         | 378kB 48.8MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 389kB 49.6MB/s eta 0:00:01\r\u001b[K    20% |██████▌                         | 399kB 12.3MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 409kB 12.2MB/s eta 0:00:01\r\u001b[K    21% |██████▉                         | 419kB 12.1MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 430kB 12.2MB/s eta 0:00:01\r\u001b[K    22% |███████                         | 440kB 12.2MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 450kB 12.4MB/s eta 0:00:01\r\u001b[K    23% |███████▍                        | 460kB 12.3MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 471kB 12.3MB/s eta 0:00:01\r\u001b[K    24% |███████▊                        | 481kB 12.3MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 491kB 12.1MB/s eta 0:00:01\r\u001b[K    25% |████████                        | 501kB 47.1MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 512kB 45.7MB/s eta 0:00:01\r\u001b[K    26% |████████▍                       | 522kB 46.5MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 532kB 47.4MB/s eta 0:00:01\r\u001b[K    27% |████████▊                       | 542kB 11.2MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 552kB 11.3MB/s eta 0:00:01\r\u001b[K    28% |█████████                       | 563kB 11.1MB/s eta 0:00:01\r\u001b[K    28% |█████████▎                      | 573kB 11.1MB/s eta 0:00:01\r\u001b[K    29% |█████████▍                      | 583kB 11.1MB/s eta 0:00:01\r\u001b[K    29% |█████████▋                      | 593kB 11.3MB/s eta 0:00:01\r\u001b[K    30% |█████████▊                      | 604kB 11.3MB/s eta 0:00:01\r\u001b[K    30% |██████████                      | 614kB 11.5MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 624kB 11.4MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 634kB 11.4MB/s eta 0:00:01\r\u001b[K    32% |██████████▍                     | 645kB 50.5MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 655kB 52.1MB/s eta 0:00:01\r\u001b[K    33% |██████████▊                     | 665kB 44.3MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 675kB 45.0MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 686kB 45.1MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 696kB 45.0MB/s eta 0:00:01\r\u001b[K    35% |███████████▍                    | 706kB 44.4MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 716kB 44.7MB/s eta 0:00:01\r\u001b[K    36% |███████████▊                    | 727kB 45.6MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 737kB 44.5MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 747kB 43.8MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 757kB 42.7MB/s eta 0:00:01\r\u001b[K    38% |████████████▍                   | 768kB 52.8MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 778kB 52.9MB/s eta 0:00:01\r\u001b[K    39% |████████████▊                   | 788kB 52.7MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 798kB 53.2MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 808kB 52.6MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 819kB 51.5MB/s eta 0:00:01\r\u001b[K    41% |█████████████▍                  | 829kB 52.7MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 839kB 53.2MB/s eta 0:00:01\r\u001b[K    42% |█████████████▊                  | 849kB 53.1MB/s eta 0:00:01\r\u001b[K    43% |█████████████▉                  | 860kB 48.4MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 870kB 48.3MB/s eta 0:00:01\r\u001b[K    44% |██████████████▏                 | 880kB 48.7MB/s eta 0:00:01\r\u001b[K    44% |██████████████▍                 | 890kB 48.8MB/s eta 0:00:01\r\u001b[K    45% |██████████████▌                 | 901kB 48.2MB/s eta 0:00:01\r\u001b[K    45% |██████████████▊                 | 911kB 49.0MB/s eta 0:00:01\r\u001b[K    46% |██████████████▉                 | 921kB 49.3MB/s eta 0:00:01\r\u001b[K    47% |███████████████                 | 931kB 48.5MB/s eta 0:00:01\r\u001b[K    47% |███████████████▏                | 942kB 48.4MB/s eta 0:00:01\r\u001b[K    48% |███████████████▍                | 952kB 47.9MB/s eta 0:00:01\r\u001b[K    48% |███████████████▌                | 962kB 54.2MB/s eta 0:00:01\r\u001b[K    49% |███████████████▊                | 972kB 54.2MB/s eta 0:00:01\r\u001b[K    49% |███████████████▉                | 983kB 53.7MB/s eta 0:00:01\r\u001b[K    50% |████████████████                | 993kB 54.2MB/s eta 0:00:01\r\u001b[K    50% |████████████████▏               | 1.0MB 54.3MB/s eta 0:00:01\r\u001b[K    51% |████████████████▍               | 1.0MB 53.4MB/s eta 0:00:01\r\u001b[K    51% |████████████████▌               | 1.0MB 53.0MB/s eta 0:00:01\r\u001b[K    52% |████████████████▊               | 1.0MB 50.6MB/s eta 0:00:01\r\u001b[K    52% |████████████████▉               | 1.0MB 51.8MB/s eta 0:00:01\r\u001b[K    53% |█████████████████               | 1.1MB 52.2MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▏              | 1.1MB 49.2MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▍              | 1.1MB 49.8MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▌              | 1.1MB 49.6MB/s eta 0:00:01\r\u001b[K    55% |█████████████████▊              | 1.1MB 43.0MB/s eta 0:00:01\r\u001b[K    55% |█████████████████▉              | 1.1MB 43.0MB/s eta 0:00:01\r\u001b[K    56% |██████████████████              | 1.1MB 43.8MB/s eta 0:00:01\r\u001b[K    56% |██████████████████▏             | 1.1MB 45.2MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▍             | 1.1MB 47.3MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▌             | 1.1MB 46.5MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▊             | 1.2MB 46.5MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▉             | 1.2MB 48.1MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 1.2MB 47.1MB/s eta 0:00:01\r\u001b[K    59% |███████████████████▏            | 1.2MB 46.4MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▍            | 1.2MB 52.1MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▌            | 1.2MB 51.7MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▊            | 1.2MB 51.6MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▉            | 1.2MB 51.2MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 1.2MB 51.8MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▏           | 1.2MB 51.9MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▍           | 1.3MB 51.9MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▌           | 1.3MB 51.9MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 1.3MB 51.4MB/s eta 0:00:01\r\u001b[K    65% |████████████████████▉           | 1.3MB 51.9MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 1.3MB 52.0MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▏          | 1.3MB 51.9MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 1.3MB 52.0MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▌          | 1.3MB 52.0MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 1.3MB 52.1MB/s eta 0:00:01\r\u001b[K    68% |█████████████████████▉          | 1.4MB 52.1MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 1.4MB 51.5MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▏         | 1.4MB 53.1MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 1.4MB 20.2MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▌         | 1.4MB 20.1MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 1.4MB 16.3MB/s eta 0:00:01\r\u001b[K    71% |██████████████████████▉         | 1.4MB 16.3MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 1.4MB 16.3MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▏        | 1.4MB 16.3MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 1.4MB 16.2MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▌        | 1.5MB 16.2MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 1.5MB 16.2MB/s eta 0:00:01\r\u001b[K    74% |███████████████████████▉        | 1.5MB 16.1MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 1.5MB 31.9MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▏       | 1.5MB 31.6MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 1.5MB 51.2MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▌       | 1.5MB 51.8MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 1.5MB 51.6MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 1.5MB 52.1MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████       | 1.5MB 52.2MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 1.6MB 51.4MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▎      | 1.6MB 52.8MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 1.6MB 54.3MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▋      | 1.6MB 44.9MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 1.6MB 46.4MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████      | 1.6MB 46.5MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 1.6MB 46.7MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▎     | 1.6MB 46.8MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 1.6MB 46.1MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▋     | 1.6MB 45.9MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 1.7MB 46.2MB/s eta 0:00:01\r\u001b[K    84% |███████████████████████████     | 1.7MB 45.7MB/s eta 0:00:01\r\u001b[K    84% |███████████████████████████▏    | 1.7MB 44.9MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▎    | 1.7MB 52.7MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▍    | 1.7MB 52.9MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▋    | 1.7MB 53.1MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▊    | 1.7MB 52.9MB/s eta 0:00:01\r\u001b[K    87% |████████████████████████████    | 1.7MB 53.3MB/s eta 0:00:01\r\u001b[K    87% |████████████████████████████    | 1.7MB 53.6MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▎   | 1.8MB 53.6MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▍   | 1.8MB 53.4MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▋   | 1.8MB 52.8MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▊   | 1.8MB 53.2MB/s eta 0:00:01\r\u001b[K    90% |█████████████████████████████   | 1.8MB 1.8MB/s eta 0:00:01\r\u001b[K    90% |█████████████████████████████   | 1.8MB 1.8MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▎  | 1.8MB 1.8MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▍  | 1.8MB 1.8MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▋  | 1.8MB 1.8MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▊  | 1.8MB 1.8MB/s eta 0:00:01\r\u001b[K    93% |██████████████████████████████  | 1.9MB 1.8MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████  | 1.9MB 1.8MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▎ | 1.9MB 1.8MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▍ | 1.9MB 1.8MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▋ | 1.9MB 35.2MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▊ | 1.9MB 36.5MB/s eta 0:00:01\r\u001b[K    96% |███████████████████████████████ | 1.9MB 36.5MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████ | 1.9MB 36.7MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▎| 1.9MB 36.6MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▍| 1.9MB 37.6MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▋| 2.0MB 37.2MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▊| 2.0MB 36.9MB/s eta 0:00:01\r\u001b[K    99% |████████████████████████████████| 2.0MB 37.4MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 2.0MB 11.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VGmoA6JR2RLd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ]
    },
    {
      "metadata": {
        "id": "Z0siCEw12RLf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this coursework you will implement one of the most commonly used model for image recognition tasks, the Residual Network. The architecture is introduced in 2015 by Kaiming He, et al. in the paper [\"Deep residual learning for image recognition\"](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf). \n",
        "<br>\n",
        "\n",
        "In a residual network, each block contains some convolutional layers, plus \"skip\" connections, which allow the activations to by pass a layer, and then be summed up with the activations of the skipped layer. The image below illustrates a building block in residual networks."
      ]
    },
    {
      "metadata": {
        "id": "Tz-2i06y2RLi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![resnet-block](https://github.com/ZHONGCHUYUN/Deep_learning_cw/blob/master/utils/resnet-block.png?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "a4AJK5Qc2RLk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Depending on the number of building blocks, resnets can have different architectures, for example ResNet-50, ResNet-101 and etc. Here you are required to build ResNet-18 to perform classification on the CIFAR-10 dataset, therefore your network will have the following architecture:"
      ]
    },
    {
      "metadata": {
        "id": "tynU-j4z2RLn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![resnet](https://github.com/ZHONGCHUYUN/Deep_learning_cw/blob/master/utils/resnet.png?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "rTi0I2uF2RLr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1 (40 points)"
      ]
    },
    {
      "metadata": {
        "id": "04X8vhXr2RLw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this part, you will use basic pytorch operations to define the 2D convolution and max pooling operation. \n"
      ]
    },
    {
      "metadata": {
        "id": "sxyDdsOb2RLy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### YOUR TASK"
      ]
    },
    {
      "metadata": {
        "id": "jVKQGk3E2RL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- implement the forward pass for Conv2D and MaxPool2D\n",
        "- You can only fill in the parts which are specified as \"YOUR CODE HERE\"\n",
        "- You are **NOT** allowed to use the torch.nn module and the conv2d/maxpooling functions in torch.nn.functional"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K0JLAagD6X4z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-PrR3_PS2RL8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Conv2D(nn.Module):\n",
        "    \n",
        "    def __init__(self, inchannel, outchannel, kernel_size, stride, padding, bias = True):\n",
        "        \n",
        "        super(Conv2D, self).__init__()\n",
        "        \n",
        "        self.inchannel = inchannel\n",
        "        self.outchannel = outchannel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        \n",
        "        self.weights = nn.Parameter(torch.Tensor(outchannel, inchannel, \n",
        "                                                 kernel_size, kernel_size))\n",
        "        self.weights.data.normal_(-0.1, 0.1)\n",
        "        \n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.Tensor(outchannel, ))\n",
        "            self.bias.data.normal_(-0.1, 0.1)\n",
        "        else:\n",
        "            self.bias = None\n",
        "            \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        ##############################################################\n",
        "        #                       YOUR CODE HERE                       #       \n",
        "        ##############################################################\n",
        "        batch_size = x.shape[0]\n",
        "        input_width = x.shape[2]\n",
        "        input_length = x.shape[3]\n",
        "\n",
        "        output_width = (input_width+2*self.padding-self.kernel_size)//self.stride+1\n",
        "        output_length = (input_length+2*self.padding-self.kernel_size)//self.stride+1\n",
        "        \n",
        "        input_unf = torch.nn.functional.unfold(x, kernel_size=self.kernel_size, padding = self.padding, stride = self.stride)\n",
        "        if self.bias:\n",
        "          output_unf = input_unf.transpose(1,2).matmul(self.weights.view(self.weights.size(0),-1).t()).transpose(1,2)+self.bias.view(-1,1)\n",
        "        else:\n",
        "          output_unf = (input_unf.transpose(1,2).matmul(self.weights.view(self.weights.size(0),-1).t()).transpose(1,2))\n",
        "        \n",
        "        \n",
        "        output = output_unf.view(batch_size, self.outchannel, output_width, output_length)\n",
        "        \n",
        "        \n",
        "\n",
        "        ##############################################################\n",
        "        #                       END OF YOUR CODE                     #\n",
        "        ##############################################################\n",
        "        \n",
        "\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wtyowszh2RMC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MaxPool2D(nn.Module):\n",
        "    \n",
        "    def __init__(self, pooling_size):\n",
        "        # assume pooling_size = kernel_size = stride\n",
        "        \n",
        "        super(MaxPool2D, self).__init__()\n",
        "        \n",
        "        self.pooling_size = pooling_size\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        \n",
        "        ##############################################################\n",
        "        #                       YOUR CODE HERE                       #       \n",
        "        ##############################################################\n",
        "#brute force#\n",
        "#         batch_size = x.shape[0]\n",
        "#         channel_size = x.shape[1]\n",
        "#         input_width = x.shape[2]\n",
        "#         input_length = x.shape[3]\n",
        "#         output_width = input_width//self.pooling_size\n",
        "#         output_length = input_length//self.pooling_size\n",
        "        \n",
        "#         output = torch.Tensor(batch_size, channel_size, output_width, output_length)\n",
        "        \n",
        "#         for b in range(batch_size):\n",
        "#           for c in range(channel_size):\n",
        "#             for w in range(output_width):\n",
        "#               for l in range(output_length):\n",
        "#                 output[b][c][w][l] = torch.max(x[b][c][(w*self.pooling_size):((w+1)*self.pooling_size),(l*self.pooling_size):((l+1)*self.pooling_size)]).item()\n",
        "       \n",
        "        x_unf = x.unfold(2,self.pooling_size, self.pooling_size).unfold(3,self.pooling_size, self.pooling_size)\n",
        "        output = x_unf.contiguous().view(x_unf.size()[:4]+(-1,)).max(dim=-1)[0]\n",
        "        \n",
        "        ##############################################################\n",
        "        #                       END OF YOUR CODE                     #\n",
        "        ##############################################################\n",
        "        \n",
        "        return output\n",
        "        \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "R2bBhs3_6X5H",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define resnet building blocks\n",
        "\n",
        "class ResidualBlock(nn.Module): \n",
        "    def __init__(self, inchannel, outchannel, stride=1): \n",
        "        \n",
        "        super(ResidualBlock, self).__init__() \n",
        "        \n",
        "        self.left = nn.Sequential(Conv2D(inchannel, outchannel, kernel_size=3, \n",
        "                                         stride=stride, padding=1, bias=False), \n",
        "                                  nn.BatchNorm2d(outchannel), \n",
        "                                  nn.ReLU(inplace=True), \n",
        "                                  Conv2D(outchannel, outchannel, kernel_size=3, \n",
        "                                         stride=1, padding=1, bias=False), \n",
        "                                  nn.BatchNorm2d(outchannel)) \n",
        "        \n",
        "        self.shortcut = nn.Sequential() \n",
        "        \n",
        "        if stride != 1 or inchannel != outchannel: \n",
        "            \n",
        "            self.shortcut = nn.Sequential(Conv2D(inchannel, outchannel, \n",
        "                                                 kernel_size=1, stride=stride, \n",
        "                                                 padding = 0, bias=False), \n",
        "                                          nn.BatchNorm2d(outchannel) ) \n",
        "            \n",
        "    def forward(self, x): \n",
        "        \n",
        "        out = self.left(x) \n",
        "        \n",
        "        out += self.shortcut(x) \n",
        "        \n",
        "        out = F.relu(out) \n",
        "        \n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "U-Sa0BAw6X5P",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define resnet\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, ResidualBlock, num_classes = 10):\n",
        "        \n",
        "        super(ResNet, self).__init__()\n",
        "        \n",
        "        self.inchannel = 64\n",
        "        self.conv1 = nn.Sequential(Conv2D(3, 64, kernel_size = 3, stride = 1,\n",
        "                                            padding = 1, bias = False), \n",
        "                                  nn.BatchNorm2d(64), \n",
        "                                  nn.ReLU())\n",
        "        \n",
        "        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride = 1)\n",
        "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride = 2)\n",
        "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride = 2)\n",
        "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride = 2)\n",
        "        self.maxpool = MaxPool2D(4)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    \n",
        "    def make_layer(self, block, channels, num_blocks, stride):\n",
        "        \n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        \n",
        "        layers = []\n",
        "        \n",
        "        for stride in strides:\n",
        "            \n",
        "            layers.append(block(self.inchannel, channels, stride))\n",
        "            \n",
        "            self.inchannel = channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        \n",
        "        return x\n",
        "    \n",
        "    \n",
        "def ResNet18():\n",
        "    return ResNet(ResidualBlock)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2XbVhfqI2RMQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 2 (40 points)"
      ]
    },
    {
      "metadata": {
        "id": "SnFPynak2RMS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this part, you will train the ResNet-18 defined in the previous part on the CIFAR-10 dataset. Code for loading the dataset, training and evaluation are provided. "
      ]
    },
    {
      "metadata": {
        "id": "pZnLfWtz2RMT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Your Task"
      ]
    },
    {
      "metadata": {
        "id": "t78doYMz2RMV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Train your network to achieve the best possible test set accuracy after a maximum of 10 epochs of training.\n",
        "\n",
        "2. You can use techniques such as optimal hyper-parameter searching, data pre-processing\n",
        "\n",
        "3. If necessary, you can also use another optimiser\n",
        "\n",
        "4. **Answer the following question:**\n",
        "Given such a network with a large number of trainable parameters, and a training set of a large number of data, what do you think is the best strategy for hyperparameter searching? "
      ]
    },
    {
      "metadata": {
        "id": "DgF9lp4Z2RMW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**YOUR ANSWER FOR 2.4 HERE**\n",
        "\n",
        "I think Bayesian optimization is the best algorithm compared to grid search and random search. Because using Bayesian Optimization can help to speed up the process by reducing the computation task.\n",
        "A:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jx4EjUPa6X5d",
        "outputId": "feb8b97b-60bd-4c1b-8d64-86b30a5b9b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "\n",
        "transform = T.ToTensor()\n",
        "\n",
        "\n",
        "# load data\n",
        "\n",
        "NUM_TRAIN = 49000\n",
        "print_every = 100\n",
        "\n",
        "##normalization data##\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "data_dir = './data'\n",
        "cifar10_train = dset.CIFAR10(data_dir, train=True, download=True, transform=transform_train)\n",
        "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "cifar10_val = dset.CIFAR10(data_dir, train=True, download=True, transform=transform_val)\n",
        "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
        "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "cifar10_test = dset.CIFAR10(data_dir, train=False, download=True, transform=transform_test)\n",
        "loader_test = DataLoader(cifar10_test, batch_size=64)\n",
        "\n",
        "\n",
        "USE_GPU = True\n",
        "dtype = torch.float32 \n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Lcscd7k66X5s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "    # function for test accuracy on validation and test set\n",
        "    \n",
        "    if loader.dataset.train:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return 100*acc\n",
        "\n",
        "\n",
        "def train_part(model, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        print(len(loader_train))\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters of the model using the gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print('Epoch: %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
        "                #check_accuracy(loader_val, model)\n",
        "                print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-RG8rNexjRx",
        "colab_type": "code",
        "outputId": "f30ec21c-1d75-4689-a410-7d1a5e413524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install GPy"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/7d/e55ffc3b16b68e8b50ccecacec56715bcf49d5c2f204f5ba60374d419611/GPy-1.9.6.tar.gz (873kB)\n",
            "\r\u001b[K    1% |▍                               | 10kB 16.2MB/s eta 0:00:01\r\u001b[K    2% |▊                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K    3% |█▏                              | 30kB 3.2MB/s eta 0:00:01\r\u001b[K    4% |█▌                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K    5% |█▉                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 61kB 3.1MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K    9% |███                             | 81kB 4.1MB/s eta 0:00:01\r\u001b[K    10% |███▍                            | 92kB 4.5MB/s eta 0:00:01\r\u001b[K    11% |███▊                            | 102kB 3.5MB/s eta 0:00:01\r\u001b[K    12% |████▏                           | 112kB 3.5MB/s eta 0:00:01\r\u001b[K    14% |████▌                           | 122kB 5.0MB/s eta 0:00:01\r\u001b[K    15% |████▉                           | 133kB 5.0MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 143kB 9.3MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 153kB 9.4MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 163kB 9.4MB/s eta 0:00:01\r\u001b[K    19% |██████▍                         | 174kB 9.2MB/s eta 0:00:01\r\u001b[K    21% |██████▊                         | 184kB 9.3MB/s eta 0:00:01\r\u001b[K    22% |███████▏                        | 194kB 9.4MB/s eta 0:00:01\r\u001b[K    23% |███████▌                        | 204kB 43.3MB/s eta 0:00:01\r\u001b[K    24% |███████▉                        | 215kB 10.5MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 225kB 10.5MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 235kB 10.6MB/s eta 0:00:01\r\u001b[K    28% |█████████                       | 245kB 10.5MB/s eta 0:00:01\r\u001b[K    29% |█████████▍                      | 256kB 10.5MB/s eta 0:00:01\r\u001b[K    30% |█████████▊                      | 266kB 10.2MB/s eta 0:00:01\r\u001b[K    31% |██████████▏                     | 276kB 10.4MB/s eta 0:00:01\r\u001b[K    32% |██████████▌                     | 286kB 10.4MB/s eta 0:00:01\r\u001b[K    33% |██████████▉                     | 296kB 10.4MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 307kB 10.6MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 317kB 46.1MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 327kB 45.1MB/s eta 0:00:01\r\u001b[K    38% |████████████▍                   | 337kB 46.9MB/s eta 0:00:01\r\u001b[K    39% |████████████▊                   | 348kB 39.5MB/s eta 0:00:01\r\u001b[K    41% |█████████████▏                  | 358kB 38.8MB/s eta 0:00:01\r\u001b[K    42% |█████████████▌                  | 368kB 42.3MB/s eta 0:00:01\r\u001b[K    43% |█████████████▉                  | 378kB 42.1MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 389kB 41.4MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 399kB 12.3MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 409kB 12.2MB/s eta 0:00:01\r\u001b[K    48% |███████████████▍                | 419kB 12.2MB/s eta 0:00:01\r\u001b[K    49% |███████████████▊                | 430kB 12.1MB/s eta 0:00:01\r\u001b[K    50% |████████████████▏               | 440kB 12.1MB/s eta 0:00:01\r\u001b[K    51% |████████████████▌               | 450kB 12.6MB/s eta 0:00:01\r\u001b[K    52% |████████████████▉               | 460kB 12.6MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 471kB 12.7MB/s eta 0:00:01\r\u001b[K    55% |█████████████████▋              | 481kB 12.7MB/s eta 0:00:01\r\u001b[K    56% |██████████████████              | 491kB 12.8MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▍             | 501kB 47.4MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▊             | 512kB 46.0MB/s eta 0:00:01\r\u001b[K    59% |███████████████████▏            | 522kB 47.0MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▌            | 532kB 50.4MB/s eta 0:00:01\r\u001b[K    62% |███████████████████▉            | 542kB 50.3MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 552kB 54.6MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 563kB 54.5MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 573kB 52.8MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▍          | 583kB 51.8MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▊          | 593kB 50.6MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▏         | 604kB 50.5MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▌         | 614kB 54.3MB/s eta 0:00:01\r\u001b[K    71% |██████████████████████▉         | 624kB 53.8MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 634kB 53.7MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 645kB 14.5MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████        | 655kB 14.2MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▍       | 665kB 13.3MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▊       | 675kB 13.3MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 686kB 13.3MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 696kB 13.4MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 706kB 13.4MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▎     | 716kB 13.5MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▋     | 727kB 12.9MB/s eta 0:00:01\r\u001b[K    84% |███████████████████████████     | 737kB 12.8MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▍    | 747kB 36.6MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▊    | 757kB 38.3MB/s eta 0:00:01\r\u001b[K    87% |████████████████████████████▏   | 768kB 46.3MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 778kB 46.6MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 788kB 45.9MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▎  | 798kB 46.2MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▋  | 808kB 46.5MB/s eta 0:00:01\r\u001b[K    93% |██████████████████████████████  | 819kB 46.4MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▍ | 829kB 54.1MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▊ | 839kB 54.4MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 849kB 53.7MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 860kB 48.5MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 870kB 48.8MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 880kB 21.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from GPy) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from GPy) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy) (1.11.0)\n",
            "Collecting paramz>=0.9.0 (from GPy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/78/b0f0164a32518bfd3b98cb2e149b7a4d5504d13fb503b31a6c59b958ed18/paramz-0.9.4.tar.gz (70kB)\n",
            "\r\u001b[K    14% |████▋                           | 10kB 19.6MB/s eta 0:00:01\r\u001b[K    28% |█████████▎                      | 20kB 26.0MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 30kB 31.0MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▌             | 40kB 34.2MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▏        | 51kB 36.5MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▉    | 61kB 38.1MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 71kB 24.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy) (4.3.2)\n",
            "Building wheels for collected packages: GPy, paramz\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/82/1d/32a361e1ff2b4d9129a60343831dd99cdc74440e2db1c55264\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a9/fc/74/3bbd263c43ed98d67343df24cebf0a0ee34afee40d769fda9c\n",
            "Successfully built GPy paramz\n",
            "Installing collected packages: paramz, GPy\n",
            "Successfully installed GPy-1.9.6 paramz-0.9.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jSRyE2_MyM4X",
        "colab_type": "code",
        "outputId": "713a3fce-35fe-40ba-b0b3-aedc7188f9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install GPyOpt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPyOpt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/40/ca8f080d74d9f4e29069faa944fcfb083e8693b6daaba0f1e4bc65c88650/GPyOpt-1.2.5.tar.gz (55kB)\n",
            "\r\u001b[K    18% |██████                          | 10kB 16.1MB/s eta 0:00:01\r\u001b[K    37% |███████████▉                    | 20kB 2.2MB/s eta 0:00:01\r\u001b[K    55% |█████████████████▉              | 30kB 3.2MB/s eta 0:00:01\r\u001b[K    74% |███████████████████████▊        | 40kB 2.1MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▊  | 51kB 2.6MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from GPyOpt) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from GPyOpt) (1.1.0)\n",
            "Requirement already satisfied: GPy>=1.8 in /usr/local/lib/python3.6/dist-packages (from GPyOpt) (1.9.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy>=1.8->GPyOpt) (1.11.0)\n",
            "Requirement already satisfied: paramz>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from GPy>=1.8->GPyOpt) (0.9.4)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy>=1.8->GPyOpt) (4.3.2)\n",
            "Building wheels for collected packages: GPyOpt\n",
            "  Building wheel for GPyOpt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/33/1d/87/dc02440831ba986b1547dd11a7dcd44e893b0527083066d869\n",
            "Successfully built GPyOpt\n",
            "Installing collected packages: GPyOpt\n",
            "Successfully installed GPyOpt-1.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LcJfnjqrYueH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "no8o-2VS6X5y",
        "scrolled": false,
        "outputId": "b38d9c04-fa4b-4b90-83f7-162bc92f3fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12149
        }
      },
      "cell_type": "code",
      "source": [
        "# code for optimising your network performance\n",
        "\n",
        "##############################################################\n",
        "#                       YOUR CODE HERE                       #       \n",
        "##############################################################\n",
        "import GPy\n",
        "import GPyOpt\n",
        "from numpy.random import seed\n",
        "import matplotlib\n",
        "######using random search######\n",
        "# from hyperopt import hp\n",
        "# from hyperopt import fmin\n",
        "# from hyperopt import Trials\n",
        "# from hyperopt import tpe\n",
        "# from hyperopt import STATUS_OK\n",
        "\n",
        "# MAX_EVALS = 20\n",
        "\n",
        "# def objective(params):\n",
        "#   model = ResNet18()\n",
        "  \n",
        "#   optimizer = optim.Adam(model.parameters(), lr = params['learning_rate'], betas = (params['beta0'], params['beta1']), eps = params['eps'], weight_decay = params['weight_decay'])\n",
        "  \n",
        "#   train_part(model, optimizer, epochs = 10)\n",
        "  \n",
        "#   loss = 1 - check_accuracy(loader_test, model)\n",
        "\n",
        "#   return {'loss': loss, 'params': params, 'status': STATUS_OK}\n",
        "\n",
        "# # Learning rate log uniform distribution\n",
        "\n",
        "                                                \n",
        "# space = {\n",
        "#     'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.1)),\n",
        "#     'beta0': hp.uniform('beta0', 0.1, 0.999),\n",
        "#     'beta1': hp.uniform('beta1', 0.1, 0.999),\n",
        "#     'eps': hp.uniform('eps', 1e-8, 1e-5),\n",
        "#     'weight_decay':hp.uniform('weight_decay',0,0.5)\n",
        "# }\n",
        " \n",
        "# bayes_trials = Trials()               \n",
        "                                                    \n",
        "# best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = MAX_EVALS, trials = bayes_trials)\n",
        "\n",
        "\n",
        "\n",
        "def objective(bounds):\n",
        "  bounds = bounds.squeeze()\n",
        "  model = ResNet18()\n",
        "  print(bounds)\n",
        "  optimizer = optim.Adam(model.parameters(), lr = bounds[0], weight_decay = bounds[1])\n",
        "  \n",
        "  train_part(model,optimizer, epochs = 10)\n",
        "  loss = 1-check_accuracy(loader_val, model)\n",
        "  return loss\n",
        "  \n",
        "bounds = [{'name':'learning_rate','type':'continuous','domain':(0,0.01)},\n",
        "         {'name':'weight_decay','type':'continuous','domain':(0,0.01)}]\n",
        "\n",
        "#seed(78)\n",
        "X = np.zeros((1, 2))\n",
        "X[0][0] = 0.001\n",
        "X[0][1] = 0.0002\n",
        "\n",
        "myBopt = GPyOpt.methods.BayesianOptimization(f = objective, X = X, domain = bounds, model_type = 'GP', acquisition_type='EI')\n",
        "max_iter = 3\n",
        "print(\"Running the run_optimization\")\n",
        "myBopt.run_optimization(max_iter = max_iter)\n",
        "\n",
        "##############################################################\n",
        "#                       END OF YOUR CODE                     #\n",
        "##############################################################\n",
        "\n",
        "best_param = myBopt.x_opt\n",
        "print(best_param)\n",
        "model = ResNet18()\n",
        "optimizer = optim.Adam(model.parameters(), best_param[0], best_param[1])\n",
        "\n",
        "#report test set accuracy\n",
        "\n",
        "check_accuracy(loader_test, model)\n",
        "\n",
        "\n",
        "# # save the model\n",
        "# torch.save(model.state_dict(), 'model.pt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.001  0.0002]\n",
            "766\n",
            "Epoch: 0, Iteration 0, loss = 2.4296\n",
            "\n",
            "Epoch: 0, Iteration 100, loss = 2.2800\n",
            "\n",
            "Epoch: 0, Iteration 200, loss = 2.2539\n",
            "\n",
            "Epoch: 0, Iteration 300, loss = 2.0903\n",
            "\n",
            "Epoch: 0, Iteration 400, loss = 1.9640\n",
            "\n",
            "Epoch: 0, Iteration 500, loss = 1.8620\n",
            "\n",
            "Epoch: 0, Iteration 600, loss = 1.7371\n",
            "\n",
            "Epoch: 0, Iteration 700, loss = 1.7977\n",
            "\n",
            "766\n",
            "Epoch: 1, Iteration 0, loss = 1.4120\n",
            "\n",
            "Epoch: 1, Iteration 100, loss = 1.6801\n",
            "\n",
            "Epoch: 1, Iteration 200, loss = 1.8561\n",
            "\n",
            "Epoch: 1, Iteration 300, loss = 1.3113\n",
            "\n",
            "Epoch: 1, Iteration 400, loss = 1.3397\n",
            "\n",
            "Epoch: 1, Iteration 500, loss = 1.5381\n",
            "\n",
            "Epoch: 1, Iteration 600, loss = 1.1501\n",
            "\n",
            "Epoch: 1, Iteration 700, loss = 1.3801\n",
            "\n",
            "766\n",
            "Epoch: 2, Iteration 0, loss = 1.1913\n",
            "\n",
            "Epoch: 2, Iteration 100, loss = 1.2196\n",
            "\n",
            "Epoch: 2, Iteration 200, loss = 0.8565\n",
            "\n",
            "Epoch: 2, Iteration 300, loss = 0.9398\n",
            "\n",
            "Epoch: 2, Iteration 400, loss = 0.9702\n",
            "\n",
            "Epoch: 2, Iteration 500, loss = 0.8242\n",
            "\n",
            "Epoch: 2, Iteration 600, loss = 0.6908\n",
            "\n",
            "Epoch: 2, Iteration 700, loss = 0.7957\n",
            "\n",
            "766\n",
            "Epoch: 3, Iteration 0, loss = 0.9738\n",
            "\n",
            "Epoch: 3, Iteration 100, loss = 0.6319\n",
            "\n",
            "Epoch: 3, Iteration 200, loss = 0.9502\n",
            "\n",
            "Epoch: 3, Iteration 300, loss = 0.5959\n",
            "\n",
            "Epoch: 3, Iteration 400, loss = 0.7485\n",
            "\n",
            "Epoch: 3, Iteration 500, loss = 0.7121\n",
            "\n",
            "Epoch: 3, Iteration 600, loss = 0.6027\n",
            "\n",
            "Epoch: 3, Iteration 700, loss = 0.6927\n",
            "\n",
            "766\n",
            "Epoch: 4, Iteration 0, loss = 0.8933\n",
            "\n",
            "Epoch: 4, Iteration 100, loss = 0.9136\n",
            "\n",
            "Epoch: 4, Iteration 200, loss = 0.5052\n",
            "\n",
            "Epoch: 4, Iteration 300, loss = 0.5925\n",
            "\n",
            "Epoch: 4, Iteration 400, loss = 0.5420\n",
            "\n",
            "Epoch: 4, Iteration 500, loss = 0.6180\n",
            "\n",
            "Epoch: 4, Iteration 600, loss = 0.5989\n",
            "\n",
            "Epoch: 4, Iteration 700, loss = 0.6227\n",
            "\n",
            "766\n",
            "Epoch: 5, Iteration 0, loss = 0.4442\n",
            "\n",
            "Epoch: 5, Iteration 100, loss = 0.3161\n",
            "\n",
            "Epoch: 5, Iteration 200, loss = 0.4309\n",
            "\n",
            "Epoch: 5, Iteration 300, loss = 0.5733\n",
            "\n",
            "Epoch: 5, Iteration 400, loss = 0.5078\n",
            "\n",
            "Epoch: 5, Iteration 500, loss = 0.5075\n",
            "\n",
            "Epoch: 5, Iteration 600, loss = 0.6703\n",
            "\n",
            "Epoch: 5, Iteration 700, loss = 0.6753\n",
            "\n",
            "766\n",
            "Epoch: 6, Iteration 0, loss = 0.3039\n",
            "\n",
            "Epoch: 6, Iteration 100, loss = 0.5189\n",
            "\n",
            "Epoch: 6, Iteration 200, loss = 0.5684\n",
            "\n",
            "Epoch: 6, Iteration 300, loss = 0.4577\n",
            "\n",
            "Epoch: 6, Iteration 400, loss = 0.6899\n",
            "\n",
            "Epoch: 6, Iteration 500, loss = 0.3573\n",
            "\n",
            "Epoch: 6, Iteration 600, loss = 0.5067\n",
            "\n",
            "Epoch: 6, Iteration 700, loss = 0.4046\n",
            "\n",
            "766\n",
            "Epoch: 7, Iteration 0, loss = 0.3992\n",
            "\n",
            "Epoch: 7, Iteration 100, loss = 0.3223\n",
            "\n",
            "Epoch: 7, Iteration 200, loss = 0.4920\n",
            "\n",
            "Epoch: 7, Iteration 300, loss = 0.3913\n",
            "\n",
            "Epoch: 7, Iteration 400, loss = 0.5373\n",
            "\n",
            "Epoch: 7, Iteration 500, loss = 0.5694\n",
            "\n",
            "Epoch: 7, Iteration 600, loss = 0.3170\n",
            "\n",
            "Epoch: 7, Iteration 700, loss = 0.4477\n",
            "\n",
            "766\n",
            "Epoch: 8, Iteration 0, loss = 0.5529\n",
            "\n",
            "Epoch: 8, Iteration 100, loss = 0.3317\n",
            "\n",
            "Epoch: 8, Iteration 200, loss = 0.6094\n",
            "\n",
            "Epoch: 8, Iteration 300, loss = 0.4475\n",
            "\n",
            "Epoch: 8, Iteration 400, loss = 0.5322\n",
            "\n",
            "Epoch: 8, Iteration 500, loss = 0.3326\n",
            "\n",
            "Epoch: 8, Iteration 600, loss = 0.5178\n",
            "\n",
            "Epoch: 8, Iteration 700, loss = 0.3684\n",
            "\n",
            "766\n",
            "Epoch: 9, Iteration 0, loss = 0.4120\n",
            "\n",
            "Epoch: 9, Iteration 100, loss = 0.4502\n",
            "\n",
            "Epoch: 9, Iteration 200, loss = 0.4562\n",
            "\n",
            "Epoch: 9, Iteration 300, loss = 0.2586\n",
            "\n",
            "Epoch: 9, Iteration 400, loss = 0.2729\n",
            "\n",
            "Epoch: 9, Iteration 500, loss = 0.2377\n",
            "\n",
            "Epoch: 9, Iteration 600, loss = 0.3032\n",
            "\n",
            "Epoch: 9, Iteration 700, loss = 0.3437\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 829 / 1000 correct (82.90)\n",
            "Running the run_optimization\n",
            "[0.00266796 0.00164117]\n",
            "766\n",
            "Epoch: 0, Iteration 0, loss = 2.6767\n",
            "\n",
            "Epoch: 0, Iteration 100, loss = 2.1841\n",
            "\n",
            "Epoch: 0, Iteration 200, loss = 2.1060\n",
            "\n",
            "Epoch: 0, Iteration 300, loss = 1.9860\n",
            "\n",
            "Epoch: 0, Iteration 400, loss = 1.8759\n",
            "\n",
            "Epoch: 0, Iteration 500, loss = 1.6855\n",
            "\n",
            "Epoch: 0, Iteration 600, loss = 1.8628\n",
            "\n",
            "Epoch: 0, Iteration 700, loss = 1.4521\n",
            "\n",
            "766\n",
            "Epoch: 1, Iteration 0, loss = 1.4175\n",
            "\n",
            "Epoch: 1, Iteration 100, loss = 1.4253\n",
            "\n",
            "Epoch: 1, Iteration 200, loss = 1.1902\n",
            "\n",
            "Epoch: 1, Iteration 300, loss = 1.2948\n",
            "\n",
            "Epoch: 1, Iteration 400, loss = 1.1274\n",
            "\n",
            "Epoch: 1, Iteration 500, loss = 1.2396\n",
            "\n",
            "Epoch: 1, Iteration 600, loss = 1.0588\n",
            "\n",
            "Epoch: 1, Iteration 700, loss = 1.0491\n",
            "\n",
            "766\n",
            "Epoch: 2, Iteration 0, loss = 1.2315\n",
            "\n",
            "Epoch: 2, Iteration 100, loss = 1.1506\n",
            "\n",
            "Epoch: 2, Iteration 200, loss = 1.2719\n",
            "\n",
            "Epoch: 2, Iteration 300, loss = 1.1363\n",
            "\n",
            "Epoch: 2, Iteration 400, loss = 0.9811\n",
            "\n",
            "Epoch: 2, Iteration 500, loss = 0.9048\n",
            "\n",
            "Epoch: 2, Iteration 600, loss = 1.1141\n",
            "\n",
            "Epoch: 2, Iteration 700, loss = 1.0103\n",
            "\n",
            "766\n",
            "Epoch: 3, Iteration 0, loss = 0.8447\n",
            "\n",
            "Epoch: 3, Iteration 100, loss = 0.7665\n",
            "\n",
            "Epoch: 3, Iteration 200, loss = 1.2475\n",
            "\n",
            "Epoch: 3, Iteration 300, loss = 0.8971\n",
            "\n",
            "Epoch: 3, Iteration 400, loss = 1.0016\n",
            "\n",
            "Epoch: 3, Iteration 500, loss = 0.7332\n",
            "\n",
            "Epoch: 3, Iteration 600, loss = 0.6700\n",
            "\n",
            "Epoch: 3, Iteration 700, loss = 0.6892\n",
            "\n",
            "766\n",
            "Epoch: 4, Iteration 0, loss = 0.8739\n",
            "\n",
            "Epoch: 4, Iteration 100, loss = 0.8244\n",
            "\n",
            "Epoch: 4, Iteration 200, loss = 0.8854\n",
            "\n",
            "Epoch: 4, Iteration 300, loss = 0.8102\n",
            "\n",
            "Epoch: 4, Iteration 400, loss = 0.9707\n",
            "\n",
            "Epoch: 4, Iteration 500, loss = 0.5809\n",
            "\n",
            "Epoch: 4, Iteration 600, loss = 0.7852\n",
            "\n",
            "Epoch: 4, Iteration 700, loss = 0.9476\n",
            "\n",
            "766\n",
            "Epoch: 5, Iteration 0, loss = 0.9138\n",
            "\n",
            "Epoch: 5, Iteration 100, loss = 0.8258\n",
            "\n",
            "Epoch: 5, Iteration 200, loss = 0.7957\n",
            "\n",
            "Epoch: 5, Iteration 300, loss = 0.6331\n",
            "\n",
            "Epoch: 5, Iteration 400, loss = 0.8755\n",
            "\n",
            "Epoch: 5, Iteration 500, loss = 0.9919\n",
            "\n",
            "Epoch: 5, Iteration 600, loss = 0.7056\n",
            "\n",
            "Epoch: 5, Iteration 700, loss = 0.8130\n",
            "\n",
            "766\n",
            "Epoch: 6, Iteration 0, loss = 0.9724\n",
            "\n",
            "Epoch: 6, Iteration 100, loss = 0.7855\n",
            "\n",
            "Epoch: 6, Iteration 200, loss = 0.9334\n",
            "\n",
            "Epoch: 6, Iteration 300, loss = 0.6706\n",
            "\n",
            "Epoch: 6, Iteration 400, loss = 0.8472\n",
            "\n",
            "Epoch: 6, Iteration 500, loss = 0.7629\n",
            "\n",
            "Epoch: 6, Iteration 600, loss = 0.8869\n",
            "\n",
            "Epoch: 6, Iteration 700, loss = 1.0475\n",
            "\n",
            "766\n",
            "Epoch: 7, Iteration 0, loss = 0.7418\n",
            "\n",
            "Epoch: 7, Iteration 100, loss = 1.1387\n",
            "\n",
            "Epoch: 7, Iteration 200, loss = 0.6091\n",
            "\n",
            "Epoch: 7, Iteration 300, loss = 0.6306\n",
            "\n",
            "Epoch: 7, Iteration 400, loss = 0.6378\n",
            "\n",
            "Epoch: 7, Iteration 500, loss = 0.6188\n",
            "\n",
            "Epoch: 7, Iteration 600, loss = 0.5328\n",
            "\n",
            "Epoch: 7, Iteration 700, loss = 0.7301\n",
            "\n",
            "766\n",
            "Epoch: 8, Iteration 0, loss = 0.8335\n",
            "\n",
            "Epoch: 8, Iteration 100, loss = 0.8407\n",
            "\n",
            "Epoch: 8, Iteration 200, loss = 1.0238\n",
            "\n",
            "Epoch: 8, Iteration 300, loss = 0.6661\n",
            "\n",
            "Epoch: 8, Iteration 400, loss = 0.6310\n",
            "\n",
            "Epoch: 8, Iteration 500, loss = 0.8437\n",
            "\n",
            "Epoch: 8, Iteration 600, loss = 0.6375\n",
            "\n",
            "Epoch: 8, Iteration 700, loss = 0.6767\n",
            "\n",
            "766\n",
            "Epoch: 9, Iteration 0, loss = 0.6379\n",
            "\n",
            "Epoch: 9, Iteration 100, loss = 0.8646\n",
            "\n",
            "Epoch: 9, Iteration 200, loss = 0.9280\n",
            "\n",
            "Epoch: 9, Iteration 300, loss = 0.9722\n",
            "\n",
            "Epoch: 9, Iteration 400, loss = 0.7263\n",
            "\n",
            "Epoch: 9, Iteration 500, loss = 0.8754\n",
            "\n",
            "Epoch: 9, Iteration 600, loss = 1.0347\n",
            "\n",
            "Epoch: 9, Iteration 700, loss = 0.7472\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 707 / 1000 correct (70.70)\n",
            "[0.00024882 0.00828589]\n",
            "766\n",
            "Epoch: 0, Iteration 0, loss = 2.5947\n",
            "\n",
            "Epoch: 0, Iteration 100, loss = 2.2888\n",
            "\n",
            "Epoch: 0, Iteration 200, loss = 2.3145\n",
            "\n",
            "Epoch: 0, Iteration 300, loss = 2.2763\n",
            "\n",
            "Epoch: 0, Iteration 400, loss = 2.2650\n",
            "\n",
            "Epoch: 0, Iteration 500, loss = 2.2538\n",
            "\n",
            "Epoch: 0, Iteration 600, loss = 2.2643\n",
            "\n",
            "Epoch: 0, Iteration 700, loss = 2.2656\n",
            "\n",
            "766\n",
            "Epoch: 1, Iteration 0, loss = 2.2607\n",
            "\n",
            "Epoch: 1, Iteration 100, loss = 2.2061\n",
            "\n",
            "Epoch: 1, Iteration 200, loss = 2.1905\n",
            "\n",
            "Epoch: 1, Iteration 300, loss = 1.9932\n",
            "\n",
            "Epoch: 1, Iteration 400, loss = 2.0407\n",
            "\n",
            "Epoch: 1, Iteration 500, loss = 1.9553\n",
            "\n",
            "Epoch: 1, Iteration 600, loss = 1.8182\n",
            "\n",
            "Epoch: 1, Iteration 700, loss = 1.8987\n",
            "\n",
            "766\n",
            "Epoch: 2, Iteration 0, loss = 1.6913\n",
            "\n",
            "Epoch: 2, Iteration 100, loss = 1.7033\n",
            "\n",
            "Epoch: 2, Iteration 200, loss = 1.6175\n",
            "\n",
            "Epoch: 2, Iteration 300, loss = 1.6273\n",
            "\n",
            "Epoch: 2, Iteration 400, loss = 1.4983\n",
            "\n",
            "Epoch: 2, Iteration 500, loss = 1.3634\n",
            "\n",
            "Epoch: 2, Iteration 600, loss = 1.3167\n",
            "\n",
            "Epoch: 2, Iteration 700, loss = 1.3374\n",
            "\n",
            "766\n",
            "Epoch: 3, Iteration 0, loss = 1.2099\n",
            "\n",
            "Epoch: 3, Iteration 100, loss = 1.0444\n",
            "\n",
            "Epoch: 3, Iteration 200, loss = 1.0315\n",
            "\n",
            "Epoch: 3, Iteration 300, loss = 1.0365\n",
            "\n",
            "Epoch: 3, Iteration 400, loss = 1.0214\n",
            "\n",
            "Epoch: 3, Iteration 500, loss = 0.9784\n",
            "\n",
            "Epoch: 3, Iteration 600, loss = 0.9957\n",
            "\n",
            "Epoch: 3, Iteration 700, loss = 0.9527\n",
            "\n",
            "766\n",
            "Epoch: 4, Iteration 0, loss = 1.1316\n",
            "\n",
            "Epoch: 4, Iteration 100, loss = 0.8488\n",
            "\n",
            "Epoch: 4, Iteration 200, loss = 0.8397\n",
            "\n",
            "Epoch: 4, Iteration 300, loss = 0.9370\n",
            "\n",
            "Epoch: 4, Iteration 400, loss = 0.7391\n",
            "\n",
            "Epoch: 4, Iteration 500, loss = 0.6826\n",
            "\n",
            "Epoch: 4, Iteration 600, loss = 0.6770\n",
            "\n",
            "Epoch: 4, Iteration 700, loss = 0.7446\n",
            "\n",
            "766\n",
            "Epoch: 5, Iteration 0, loss = 0.7953\n",
            "\n",
            "Epoch: 5, Iteration 100, loss = 0.8290\n",
            "\n",
            "Epoch: 5, Iteration 200, loss = 0.6895\n",
            "\n",
            "Epoch: 5, Iteration 300, loss = 0.6043\n",
            "\n",
            "Epoch: 5, Iteration 400, loss = 0.7839\n",
            "\n",
            "Epoch: 5, Iteration 500, loss = 0.7792\n",
            "\n",
            "Epoch: 5, Iteration 600, loss = 1.0028\n",
            "\n",
            "Epoch: 5, Iteration 700, loss = 0.8151\n",
            "\n",
            "766\n",
            "Epoch: 6, Iteration 0, loss = 0.5022\n",
            "\n",
            "Epoch: 6, Iteration 100, loss = 0.5646\n",
            "\n",
            "Epoch: 6, Iteration 200, loss = 0.7088\n",
            "\n",
            "Epoch: 6, Iteration 300, loss = 0.5150\n",
            "\n",
            "Epoch: 6, Iteration 400, loss = 0.7455\n",
            "\n",
            "Epoch: 6, Iteration 500, loss = 0.5783\n",
            "\n",
            "Epoch: 6, Iteration 600, loss = 0.8423\n",
            "\n",
            "Epoch: 6, Iteration 700, loss = 0.6809\n",
            "\n",
            "766\n",
            "Epoch: 7, Iteration 0, loss = 0.5238\n",
            "\n",
            "Epoch: 7, Iteration 100, loss = 0.6085\n",
            "\n",
            "Epoch: 7, Iteration 200, loss = 0.5141\n",
            "\n",
            "Epoch: 7, Iteration 300, loss = 0.5283\n",
            "\n",
            "Epoch: 7, Iteration 400, loss = 0.5657\n",
            "\n",
            "Epoch: 7, Iteration 500, loss = 0.7383\n",
            "\n",
            "Epoch: 7, Iteration 600, loss = 0.6217\n",
            "\n",
            "Epoch: 7, Iteration 700, loss = 0.5899\n",
            "\n",
            "766\n",
            "Epoch: 8, Iteration 0, loss = 0.7387\n",
            "\n",
            "Epoch: 8, Iteration 100, loss = 0.5725\n",
            "\n",
            "Epoch: 8, Iteration 200, loss = 0.5605\n",
            "\n",
            "Epoch: 8, Iteration 300, loss = 0.7463\n",
            "\n",
            "Epoch: 8, Iteration 400, loss = 0.5126\n",
            "\n",
            "Epoch: 8, Iteration 500, loss = 0.4928\n",
            "\n",
            "Epoch: 8, Iteration 600, loss = 0.4102\n",
            "\n",
            "Epoch: 8, Iteration 700, loss = 0.3849\n",
            "\n",
            "766\n",
            "Epoch: 9, Iteration 0, loss = 0.6359\n",
            "\n",
            "Epoch: 9, Iteration 100, loss = 0.6338\n",
            "\n",
            "Epoch: 9, Iteration 200, loss = 0.4837\n",
            "\n",
            "Epoch: 9, Iteration 300, loss = 0.3081\n",
            "\n",
            "Epoch: 9, Iteration 400, loss = 0.5396\n",
            "\n",
            "Epoch: 9, Iteration 500, loss = 0.4943\n",
            "\n",
            "Epoch: 9, Iteration 600, loss = 0.5851\n",
            "\n",
            "Epoch: 9, Iteration 700, loss = 0.5554\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 808 / 1000 correct (80.80)\n",
            "[0.00580039 0.007532  ]\n",
            "766\n",
            "Epoch: 0, Iteration 0, loss = 2.4158\n",
            "\n",
            "Epoch: 0, Iteration 100, loss = 1.9339\n",
            "\n",
            "Epoch: 0, Iteration 200, loss = 1.8194\n",
            "\n",
            "Epoch: 0, Iteration 300, loss = 1.8649\n",
            "\n",
            "Epoch: 0, Iteration 400, loss = 1.8704\n",
            "\n",
            "Epoch: 0, Iteration 500, loss = 1.8916\n",
            "\n",
            "Epoch: 0, Iteration 600, loss = 1.7910\n",
            "\n",
            "Epoch: 0, Iteration 700, loss = 1.6047\n",
            "\n",
            "766\n",
            "Epoch: 1, Iteration 0, loss = 1.6996\n",
            "\n",
            "Epoch: 1, Iteration 100, loss = 1.9128\n",
            "\n",
            "Epoch: 1, Iteration 200, loss = 1.7525\n",
            "\n",
            "Epoch: 1, Iteration 300, loss = 1.8487\n",
            "\n",
            "Epoch: 1, Iteration 400, loss = 1.5097\n",
            "\n",
            "Epoch: 1, Iteration 500, loss = 1.6320\n",
            "\n",
            "Epoch: 1, Iteration 600, loss = 1.4936\n",
            "\n",
            "Epoch: 1, Iteration 700, loss = 1.7332\n",
            "\n",
            "766\n",
            "Epoch: 2, Iteration 0, loss = 1.4311\n",
            "\n",
            "Epoch: 2, Iteration 100, loss = 1.6533\n",
            "\n",
            "Epoch: 2, Iteration 200, loss = 1.6839\n",
            "\n",
            "Epoch: 2, Iteration 300, loss = 1.6564\n",
            "\n",
            "Epoch: 2, Iteration 400, loss = 1.6710\n",
            "\n",
            "Epoch: 2, Iteration 500, loss = 1.5499\n",
            "\n",
            "Epoch: 2, Iteration 600, loss = 1.4022\n",
            "\n",
            "Epoch: 2, Iteration 700, loss = 1.6163\n",
            "\n",
            "766\n",
            "Epoch: 3, Iteration 0, loss = 1.3962\n",
            "\n",
            "Epoch: 3, Iteration 100, loss = 1.7210\n",
            "\n",
            "Epoch: 3, Iteration 200, loss = 1.7724\n",
            "\n",
            "Epoch: 3, Iteration 300, loss = 1.3885\n",
            "\n",
            "Epoch: 3, Iteration 400, loss = 1.3757\n",
            "\n",
            "Epoch: 3, Iteration 500, loss = 1.4309\n",
            "\n",
            "Epoch: 3, Iteration 600, loss = 1.4162\n",
            "\n",
            "Epoch: 3, Iteration 700, loss = 1.5305\n",
            "\n",
            "766\n",
            "Epoch: 4, Iteration 0, loss = 1.5653\n",
            "\n",
            "Epoch: 4, Iteration 100, loss = 1.4912\n",
            "\n",
            "Epoch: 4, Iteration 200, loss = 1.5778\n",
            "\n",
            "Epoch: 4, Iteration 300, loss = 1.2402\n",
            "\n",
            "Epoch: 4, Iteration 400, loss = 1.2370\n",
            "\n",
            "Epoch: 4, Iteration 500, loss = 1.3348\n",
            "\n",
            "Epoch: 4, Iteration 600, loss = 1.3858\n",
            "\n",
            "Epoch: 4, Iteration 700, loss = 1.4929\n",
            "\n",
            "766\n",
            "Epoch: 5, Iteration 0, loss = 1.6289\n",
            "\n",
            "Epoch: 5, Iteration 100, loss = 1.3784\n",
            "\n",
            "Epoch: 5, Iteration 200, loss = 1.5318\n",
            "\n",
            "Epoch: 5, Iteration 300, loss = 1.2822\n",
            "\n",
            "Epoch: 5, Iteration 400, loss = 1.2769\n",
            "\n",
            "Epoch: 5, Iteration 500, loss = 1.3077\n",
            "\n",
            "Epoch: 5, Iteration 600, loss = 1.5026\n",
            "\n",
            "Epoch: 5, Iteration 700, loss = 1.4525\n",
            "\n",
            "766\n",
            "Epoch: 6, Iteration 0, loss = 1.4313\n",
            "\n",
            "Epoch: 6, Iteration 100, loss = 1.3529\n",
            "\n",
            "Epoch: 6, Iteration 200, loss = 1.4943\n",
            "\n",
            "Epoch: 6, Iteration 300, loss = 1.5019\n",
            "\n",
            "Epoch: 6, Iteration 400, loss = 1.5422\n",
            "\n",
            "Epoch: 6, Iteration 500, loss = 1.4029\n",
            "\n",
            "Epoch: 6, Iteration 600, loss = 1.5310\n",
            "\n",
            "Epoch: 6, Iteration 700, loss = 1.4064\n",
            "\n",
            "766\n",
            "Epoch: 7, Iteration 0, loss = 1.7060\n",
            "\n",
            "Epoch: 7, Iteration 100, loss = 1.2064\n",
            "\n",
            "Epoch: 7, Iteration 200, loss = 1.5060\n",
            "\n",
            "Epoch: 7, Iteration 300, loss = 1.3279\n",
            "\n",
            "Epoch: 7, Iteration 400, loss = 1.4240\n",
            "\n",
            "Epoch: 7, Iteration 500, loss = 1.5066\n",
            "\n",
            "Epoch: 7, Iteration 600, loss = 1.2724\n",
            "\n",
            "Epoch: 7, Iteration 700, loss = 1.4253\n",
            "\n",
            "766\n",
            "Epoch: 8, Iteration 0, loss = 1.4241\n",
            "\n",
            "Epoch: 8, Iteration 100, loss = 1.1757\n",
            "\n",
            "Epoch: 8, Iteration 200, loss = 1.3997\n",
            "\n",
            "Epoch: 8, Iteration 300, loss = 1.5159\n",
            "\n",
            "Epoch: 8, Iteration 400, loss = 1.3338\n",
            "\n",
            "Epoch: 8, Iteration 500, loss = 1.3447\n",
            "\n",
            "Epoch: 8, Iteration 600, loss = 1.3825\n",
            "\n",
            "Epoch: 8, Iteration 700, loss = 1.3360\n",
            "\n",
            "766\n",
            "Epoch: 9, Iteration 0, loss = 1.3470\n",
            "\n",
            "Epoch: 9, Iteration 100, loss = 1.5388\n",
            "\n",
            "Epoch: 9, Iteration 200, loss = 1.3200\n",
            "\n",
            "Epoch: 9, Iteration 300, loss = 1.4764\n",
            "\n",
            "Epoch: 9, Iteration 400, loss = 1.2385\n",
            "\n",
            "Epoch: 9, Iteration 500, loss = 1.1580\n",
            "\n",
            "Epoch: 9, Iteration 600, loss = 1.1655\n",
            "\n",
            "Epoch: 9, Iteration 700, loss = 1.2191\n",
            "\n",
            "Checking accuracy on validation set\n",
            "Got 442 / 1000 correct (44.20)\n",
            "[0.001  0.0002]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0211f1b275b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m#report test set accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid epsilon value: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid beta parameter at index 0: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5DK0OTN_QA67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "6c668490-51c2-4380-b8f5-2f53a1f13c0d"
      },
      "cell_type": "code",
      "source": [
        "best_param = myBopt.x_opt\n",
        "print(best_param)\n",
        "model = ResNet18()\n",
        "optimizer = optim.Adam(model.parameters(), lr=best_param[0], weight_decay=best_param[1])\n",
        "train_part(model,optimizer, epochs = 10)\n",
        "\n",
        "#report test set accuracy\n",
        "\n",
        "check_accuracy(loader_test, model)\n",
        "\n",
        "\n",
        "# # save the model\n",
        "# torch.save(model.state_dict(), 'model.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.001  0.0002]\n",
            "766\n",
            "Epoch: 0, Iteration 0, loss = 2.6453\n",
            "\n",
            "Epoch: 0, Iteration 100, loss = 2.2592\n",
            "\n",
            "Epoch: 0, Iteration 200, loss = 2.2201\n",
            "\n",
            "Epoch: 0, Iteration 300, loss = 2.1492\n",
            "\n",
            "Epoch: 0, Iteration 400, loss = 2.0130\n",
            "\n",
            "Epoch: 0, Iteration 500, loss = 1.7181\n",
            "\n",
            "Epoch: 0, Iteration 600, loss = 1.8231\n",
            "\n",
            "Epoch: 0, Iteration 700, loss = 1.5518\n",
            "\n",
            "766\n",
            "Epoch: 1, Iteration 0, loss = 1.4204\n",
            "\n",
            "Epoch: 1, Iteration 100, loss = 1.4671\n",
            "\n",
            "Epoch: 1, Iteration 200, loss = 1.3647\n",
            "\n",
            "Epoch: 1, Iteration 300, loss = 1.2726\n",
            "\n",
            "Epoch: 1, Iteration 400, loss = 1.4012\n",
            "\n",
            "Epoch: 1, Iteration 500, loss = 1.2707\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s4jDDJKHQAH7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "NgA3aj1e16nR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "ec0f79d3-1ae5-4814-d6d7-170137babac8"
      },
      "cell_type": "code",
      "source": [
        "best_param = myBopt.x_opt\n",
        "print(best_param)\n",
        "myBopt.plot_acquisition()\n",
        "myBopt.plot_convergence()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.001  0.0002]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4UAAAFMCAYAAAB8qBn1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAFMCAYAAAB7z5DJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A4tlP5xvDhM9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Part 3 (20 points)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-HNVe5w2RMo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The code provided below will allow you to visualise the feature maps computed by different layers of your network. Run the code (install matplotlib if necessary) and **answer the following questions**: \n",
        "\n",
        "1. Compare the feature maps from low-level layers to high-level layers, what do you observe? \n",
        "\n",
        "In low-level layers, the number of feature maps is smaller than the high-level layers, and the size of each map in low-level is larger than that in high-level. Besides, the features in the low-level layers may be more simplex while there may be more features extracted in the high-level layers.\n",
        "\n",
        "2. Use the training log, reported test set accuracy and the feature maps, analyse the performance of your network. If you think the performance is sufficiently good, explain why; if not, what might be the problem and how can you improve the performance?\n",
        "\n",
        "According to the reported test set accuracy, the performance of the network has up to ..., by using the GPy package to implement Bayesian optimization and preprocessing all the data(training data, test data), it has been improved but not so sufficient due to the rest... In my opinion, the   \n",
        "\n",
        "\n",
        "3. What are the other possible ways to analyse the performance of your network?\n",
        "\n",
        "Plotting graphs of error rates. Confusion Matrix."
      ]
    },
    {
      "metadata": {
        "id": "NcJjVI1F2RMp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**YOUR ANSWER FOR PART 3 HERE**\n",
        "\n",
        "A:"
      ]
    },
    {
      "metadata": {
        "id": "lYbgNXy12RMr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "vis_labels = ['conv1', 'layer1', 'layer2', 'layer3', 'layer4']\n",
        "\n",
        "for l in vis_labels:\n",
        "\n",
        "    getattr(model, l).register_forward_hook(get_activation(l))\n",
        "    \n",
        "    \n",
        "data, _ = cifar10_test[0]\n",
        "data = data.unsqueeze_(0).to(device = device, dtype = dtype)\n",
        "\n",
        "output = model(data)\n",
        "\n",
        "\n",
        "\n",
        "for idx, l in enumerate(vis_labels):\n",
        "\n",
        "    act = activation[l].squeeze()\n",
        "\n",
        "    if idx < 2:\n",
        "        ncols = 8\n",
        "    else:\n",
        "        ncols = 32\n",
        "        \n",
        "    nrows = act.size(0) // ncols\n",
        "    \n",
        "    fig, axarr = plt.subplots(nrows, ncols)\n",
        "    fig.suptitle(l)\n",
        "\n",
        "\n",
        "    for i in range(nrows):\n",
        "        for j in range(ncols):\n",
        "            axarr[i, j].imshow(act[i * nrows + j].cpu())\n",
        "            axarr[i, j].axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sn0mHqow2RMx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**=============== END OF CW2 ===============**"
      ]
    }
  ]
}